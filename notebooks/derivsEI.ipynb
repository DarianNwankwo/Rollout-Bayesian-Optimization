{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives for expected improvement\n",
    "\n",
    "## Sanity Checks\n",
    "- Make sure we do newton iteration on the original problem\n",
    "\n",
    "Throughout these notes, we consider the derivatives of the expected improvement function needed\n",
    "for Newton's method and for differentiation of the argmax with respect to data and hyperparameters.\n",
    "We write the expected improvement acquisition function as\n",
    "$$\\begin{aligned}\n",
    "  \\alpha(x) &= \\sigma(x) g(z(x)) \\\\\n",
    "  g(z) &= z \\Phi(z) + \\phi(z) \\\\\n",
    "  z(x) &= \\sigma(x)^{-1} \\left[ \\mu(x) - f^+ - \\xi \\right]\n",
    "\\end{aligned}$$\n",
    "where $\\Phi$ and $\\phi$ denote the standard normal CDF and PDF, respectively; $f^+$ is the best function value\n",
    "found so far; and $\\xi$ is a parameter to encourage additional exploration.\n",
    "\n",
    "Throughout this note, we will use the notation $f_{,i}$ to denote $\\partial f / \\partial x_i$, and $\\dot{f}$ to denote\n",
    "differentiation with respect to data or an arbitrary hyperparameter.  Except in this initial paragraph, we will \n",
    "generally suppress the parameter $x$, leaving it implicit.  Our goal is two-fold:\n",
    "\n",
    "1.  We want to compute the derivatives necessary for Newton iteration on the problem of maximizing $\\alpha$;\n",
    "    that is, we want the gradient components $\\alpha_{,i}$ and the Hessian components $\\alpha_{,ij}$.\n",
    "2.  Given $x^*$ such that $\\alpha_{,i}(x^*) = 0$, we want to view $x^*$ as an implicit function of the\n",
    "    data and input hyper-parameters, and compute derivatives of $x^*$ via implicit differentiation:\n",
    "    $$\n",
    "      \\alpha_{,ij} \\dot{x}_j^* + \\dot{\\alpha}_{,i} = 0.\n",
    "    $$\n",
    "\n",
    "We will structure the computation from the bottom up, first differentiating the kernel function,\n",
    "then the predictive mean and variance, then $z$, and finally $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivatives for Arbitary Acquisitions in Terms of Mean, Variance and Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this note, we will use the notation $f_{,i}$ to denote $\\partial f / \\partial x_i$, and $\\dot{f}$ to denote differentiation with respect to data or an arbitrary hyperparameter. We have the evaluation of some acquisition function $\\alpha(x, \\theta)$ as the evaluation of some user-provided function $\\check{\\alpha}(\\mu(x), \\sigma(x), \\theta)$, where $\\theta \\in \\mathbb{R}^d$. Here, $\\theta$ is independent of $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using LinearAlgebra\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel derivatives\n",
    "\n",
    "We assume the kernel has the form $k(x,y) = \\psi(\\rho)$ where $\\rho = \\|r\\|$ and $r = x-y$.  Recall that\n",
    "$$\\begin{aligned}\n",
    "  \\rho &= \\sqrt{r_k r_k} \\\\\n",
    "  \\rho_{,i} &= \\rho^{-1} r_k r_{k,i} = \\rho^{-1} r_i \\\\\n",
    "  \\rho_{,ij} &= \\rho^{-1} \\delta_{ij} - \\rho^{-2} r_i \\rho_{,j} \\\\\n",
    "             &= \\rho^{-1} \\left[ \\delta_{ij} - \\rho^{-2} r_i r_j \\right]\n",
    "\\end{aligned}$$\n",
    "Applying this together with the chain rule yields\n",
    "$$\\begin{aligned}\n",
    "  k &= \\psi(\\rho) \\\\\n",
    "  k_{,i} &= \\psi'(\\rho) \\rho_{,i} = \\psi'(\\rho) \\rho^{-1} r_i \\\\\n",
    "  k_{,ij} &= \\psi''(\\rho) \\rho_{,i} \\rho_{,j} + \\psi'(\\rho) \\rho_{,ij} \\\\\n",
    "          &= \\left[ \\psi''(\\rho) - \\rho^{-1} \\psi'(\\rho) \\right] \\rho^{-2} r_i r_j + \\rho^{-1} \\psi'(\\rho) \\delta_{ij}.\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finite difference check on dψ:  2.4784095646792863e-9\n",
      "Finite difference check on d2ψ: 1.5513488841753882e-8\n",
      "Finite difference check on δψ: -1.3919287568289767e-9\n",
      "Finite difference check on δdψ: 5.518101325186929e-8\n"
     ]
    }
   ],
   "source": [
    "ψ(ρ; ℓ=1.0, σref=1.0) = σref*exp(-(ρ/ℓ)^2/2)\n",
    "dψ(ρ; ℓ=1.0, σref=1.0) = ψ(ρ, ℓ=ℓ, σref=σref) * (-ρ/(ℓ^2))\n",
    "d2ψ(ρ; ℓ=1.0, σref=1.0) = (1/ℓ^2)ψ(ρ, ℓ=ℓ, σref=σref) * (ρ^2/ℓ^2 - 1)\n",
    "\n",
    "# Perturbations to hypers\n",
    "δψ(ρ; ℓ=1.0, σref=1.0) = ψ(ρ, ℓ=ℓ, σref=σref) * (ρ^2/ℓ^3)\n",
    "# δdψ(ρ; ℓ=1.0, σref=1.0) = ψ(ρ, ℓ=ℓ, σref=σref) * -ρ/ℓ^2 * ( ρ^2/ℓ^2 + 1 )\n",
    "δdψ(ρ; ℓ=1.0, σref=1.0) = ψ(ρ, ℓ=ℓ, σref=σref)*(-ρ/ℓ^3) * (ρ^2/ℓ^2 - 2)\n",
    "\n",
    "ρ = 1.23\n",
    "h = 1e-4\n",
    "fd_dψρ = ( ψ(ρ+h)-ψ(ρ-h) )/(2h)\n",
    "fd_d2ψρ = ( ψ(ρ+h)-2*ψ(ρ)+ψ(ρ-h) )/h^2\n",
    "relerr_dψρ = (dψ(ρ) - fd_dψρ)/dψ(ρ)\n",
    "relerr_d2ψρ = (d2ψ(ρ) - fd_d2ψρ)/d2ψ(ρ)\n",
    "\n",
    "println(\"Finite difference check on dψ:  $relerr_dψρ\")\n",
    "println(\"Finite difference check on d2ψ: $relerr_d2ψρ\")\n",
    "\n",
    "fd_δψ = (ψ(ρ; ℓ=1.01+h)-ψ(ρ; ℓ=1.01-h))/(2h)\n",
    "fd_δdψ = (dψ(ρ; ℓ=1.01+h)-dψ(ρ; ℓ=1.01-h))/(2h)\n",
    "\n",
    "println(\"Finite difference check on δψ: $( (δψ(ρ, ℓ=1.01)-fd_δψ)/δψ(ρ, ℓ=1.01) )\")\n",
    "println(\"Finite difference check on δdψ: $( (δdψ(ρ, ℓ=1.01)-fd_δdψ)/δdψ(ρ, ℓ=1.01) )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check on derivative: 1.522790379504087e-8\n",
      "Check second derivative: -2.0477769216607587e-9\n",
      "Check second derivative (higher-order approx): 1.1485060675608905e-8\n",
      "Absolute Difference: 1.942890293094024e-8\n"
     ]
    }
   ],
   "source": [
    "k(x, y; ℓ=1.0, σref=1.0) = ψ(norm(x-y), ℓ=ℓ, σref=σref)\n",
    "\n",
    "function ∇k(x, y; ℓ=1.0, σref=1.0)\n",
    "    ρ = norm(x-y)\n",
    "    if ρ ≈ 0\n",
    "        # Compute the taylor expansion of ψ about zero then compute it's derivative\n",
    "        dψtaylor = taylor_expand(ρ -> dψ(ρ, ℓ=ℓ, σref=σref) / ρ, 0, order=2)(ρ) * (x-y)\n",
    "        return dψtaylor\n",
    "    end\n",
    "    return dψ(ρ, ℓ=ℓ, σref=σref) * (x-y)/ρ\n",
    "end\n",
    "\n",
    "function Hk(x, y; ℓ=1.0, σref=1.0)\n",
    "    r = x-y\n",
    "    ρ = norm(r)\n",
    "    if ρ ≈ 0\n",
    "        dψtaylor1 = taylor_expand(ρ -> (d2ψ(ρ, ℓ=ℓ, σref=σref) - dψ(ρ, ℓ=ℓ, σref=σref)/ρ)/ρ^2, 0, order=2)(ρ)\n",
    "        dψtaylor2 = taylor_expand(ρ -> dψ(ρ, ℓ=ℓ, σref=σref) / ρ, 0, order=2)(ρ)\n",
    "        return dψtaylor1 * r * r' + dψtaylor2 * I\n",
    "    end\n",
    "    return (d2ψ(ρ) - dψ(ρ)/ρ)/ρ^2 * r * r' + dψ(ρ)/ρ * I\n",
    "end\n",
    "\n",
    "δk(x, y; ℓ=1.0, σref=1.0) = δψ(norm(x-y), ℓ=ℓ, σref=σref)\n",
    "\n",
    "function δ∇k(x, y; ℓ=1.0, σref=1.0)\n",
    "    ρ = norm(x-y)\n",
    "    return δdψ(ρ, ℓ=ℓ, σref=σref) * (x-y)/ρ\n",
    "end\n",
    "\n",
    "x = rand(7)\n",
    "y = rand(7)\n",
    "u = rand(7)\n",
    "\n",
    "dk_du = ∇k(x, y)'*u\n",
    "fd_dk_du = (k(x+h*u, y)-k(x-h*u, y))/(2h)\n",
    "println(\"Check on derivative: $( (dk_du-fd_dk_du)/dk_du )\")\n",
    "\n",
    "d2k_du2 = u'*Hk(x, y)*u\n",
    "fd_d2k_du2 = ( k(x+h*u, y)-2*k(x, y)+k(x-h*u, y) )/h^2\n",
    "alt_fd_d2k_du2 = ( k(x-2h*u, y) + 4k(x-h*u, y) - 10k(x, y) + 4k(x+h*u, y) + k(x+2h*u, y) ) / 8h^2\n",
    "println(\"Check second derivative: $( (d2k_du2-fd_d2k_du2)/d2k_du2 )\")\n",
    "println(\"Check second derivative (higher-order approx): $(( d2k_du2-alt_fd_d2k_du2) / d2k_du2)\")\n",
    "println(\"Absolute Difference: $(abs(alt_fd_d2k_du2 - fd_d2k_du2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean derivatives\n",
    "\n",
    "Let $K_{XX}$ denote the kernel matrix, and $k_{Xx}$ the column vector of kernel evaluations at $x$.\n",
    "The posterior mean function for the GP (assuming a zero-mean prior) is\n",
    "$$\n",
    "  \\mu = k_{xX} c\n",
    "$$\n",
    "where $K_{XX} c = y$.  Note that $c$ does not depend on $x$, but it does depend on the data and hyperparameters.\n",
    "\n",
    "Differentiating in space is straightforward, as we only invoke the kernel derivatives:\n",
    "$$\\begin{aligned}\n",
    "  \\mu_{,i} &= k_{xX,i} c \\\\\n",
    "  \\mu_{,ij} &= k_{xX,ij} c\n",
    "\\end{aligned}$$\n",
    "Differentiating in the data and hyperparameters requires that we also differentiate through a matrix solve:\n",
    "$$\n",
    "  \\dot{\\mu} = \\dot{k}_{xX} K_{XX}^{-1} y + k_{xX} K_{XX}^{-1} \\dot{y} - k_{xX} K_{XX}^{-1} \\dot{K}_{XX} K_{XX}^{-1} y.\n",
    "$$\n",
    "Defining $d = K_{XX}^{-1} k_{Xx}$, we have\n",
    "$$\n",
    "  \\dot{\\mu} = \\dot{k}_{xX} c + d^T (\\dot{y} - \\dot{K}_{XX} c).\n",
    "$$\n",
    "Now differentiating in space and defining $K_{XX}^{-1} k_{Xx,i}$ as $w^{(i)}$, we have\n",
    "$$\n",
    "  \\dot{\\mu}_{,i} = \\dot{k}_{xX,i} c + (w^{(i)})^T (\\dot{y} - \\dot{K}_{XX} c).\n",
    "$$\n",
    "\n",
    "### Darian's Question\n",
    "Why is $(\\dot{y} - \\dot{K}_{XX} c)$ treated as a constant when differentiating in space? Don't these values depend on the spatial coordinates as well? Similarly, for $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ([0.508638256156546, 0.5069016003054393, 0.10354159519709161]) = 1.873234657321131 ≈ 1.936607837555791\n",
      "∇μ([0.508638256156546, 0.5069016003054393, 0.10354159519709161]) = [0.9208040715949356, 2.0778770943802773, 3.969283389120384] ≈ [1, 2, 4]\n",
      "Hμ([0.508638256156546, 0.5069016003054393, 0.10354159519709161]) = [1.9942970153231971 -0.5044257552393594 0.38144898287589024; -0.5044257552393594 0.9629148700798564 0.8767194314990362; 0.38144898287589024 0.8767194314990373 2.2588239041735667] ≈ 0 matrix\n",
      "Finite difference check on Hμ: 3.016895145988658e-7\n",
      "Finite difference checn on Hμ again: 1.3409464867010658e-8\n"
     ]
    }
   ],
   "source": [
    "function kernel_matrix(X, Y; ℓ=1.0, σref=1.0)\n",
    "    n = size(X)[2]\n",
    "    m = size(Y)[2]\n",
    "    K = zeros(n, m)\n",
    "    for i = 1:n\n",
    "        for j = 1:m\n",
    "            K[i,j] = k(X[:,i], Y[:,j], ℓ=ℓ, σref=σref)\n",
    "        end\n",
    "    end\n",
    "    return K\n",
    "end\n",
    "\n",
    "function μ(x, X, c; ℓ=1.0, σref=1.0)\n",
    "    μx = 0.0\n",
    "    for i = 1:size(X)[2]\n",
    "        μx += c[i] * k(x, X[:,i], ℓ=ℓ, σref=σref)\n",
    "    end\n",
    "    return μx\n",
    "end\n",
    "\n",
    "function ∇μ(x, X, c; ℓ=1.0, σref=1.0)\n",
    "    ∇μx = zeros(length(x))\n",
    "    for i = 1:size(X)[2]\n",
    "        ∇μx += c[i] * ∇k(x, X[:,i], ℓ=ℓ, σref=σref)\n",
    "    end\n",
    "    return ∇μx\n",
    "end\n",
    "\n",
    "function Hμ(x, X, c; ℓ=1.0, σref=1.0)\n",
    "    Hμx = zeros(length(x), length(x))\n",
    "    for i = 1:size(X)[2]\n",
    "        Hμx += c[i] * Hk(x, X[:,i], ℓ=ℓ, σref=σref)\n",
    "    end\n",
    "    return Hμx\n",
    "end\n",
    "\n",
    "# Set up a test problem\n",
    "\n",
    "X = rand(3, 10)\n",
    "y = X[1,:] + 2*X[2,:] + 4*X[3,:]\n",
    "KXX = kernel_matrix(X, X, ℓ=1.0, σref=1.0)\n",
    "c = KXX\\y\n",
    "\n",
    "x = rand(3)\n",
    "println(\"μ($x) = $(μ(x, X, c)) ≈ $(x[1] + 2*x[2] + 4*x[3])\")\n",
    "println(\"∇μ($x) = $(∇μ(x, X, c)) ≈ [1, 2, 4]\")\n",
    "println(\"Hμ($x) = $(Hμ(x, X, c)) ≈ 0 matrix\")\n",
    "\n",
    "u = rand(3)\n",
    "d2μ_du2 = u'*Hμ(x, X, c)*u\n",
    "fd_d2μ_du2 = (μ(x+2h*u, X, c) - 2μ(x, X, c) + μ(x-2h*u, X, c)) / 4h^2\n",
    "relerr_Hμ = (d2μ_du2 - fd_d2μ_du2) / d2μ_du2\n",
    "println(\"Finite difference check on Hμ: $(relerr_Hμ)\")\n",
    "\n",
    "# Finite difference check for Hμ\n",
    "fd_∇μ_du = u'*( ∇μ(x+h*u, X, c) - ∇μ(x-h*u, X, c) ) / (2h)\n",
    "relerr_Hμ = (d2μ_du2 - fd_∇μ_du) / d2μ_du2\n",
    "println(\"Finite difference checn on Hμ again: $(relerr_Hμ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fininte difference check for δμ: 8.576078148746327e-10\n",
      "Fininte difference check for δ∇μ: 1.583794270941519e-8\n"
     ]
    }
   ],
   "source": [
    "# δk = dk/dl * l̇\n",
    "function δμ(x, X, c, ẏ, l̇; ℓ=1.0, σref=1.0)\n",
    "    δμx = 0.0\n",
    "    KXX = kernel_matrix(X, X)\n",
    "    KXx = kernel_matrix(X, reshape(x, length(x), 1))\n",
    "    d = KXX \\ KXx\n",
    "    \n",
    "    for i = 1:size(X)[2]\n",
    "        δμx += c[i] * δk(x, X[:, i]) * l̇ + d[i]*ẏ[i]\n",
    "        for j = 1:size(X)[2]\n",
    "            δμx -= d[i] * δk(X[:, i], X[:, j]) * l̇ * c[j] \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return δμx\n",
    "end\n",
    "\n",
    "function δ∇μ(x, X, c, ẏ, l̇; ℓ=1.0, σref=1.0)\n",
    "    δ∇μx = zeros(length(x))\n",
    "    W = zeros(size(X))\n",
    "    \n",
    "    for ndx = 1:size(X)[2]\n",
    "        W[:, ndx] = ∇k(x, X[:, ndx])\n",
    "        δ∇μx += δ∇k(x, X[:, ndx]) * c[ndx] * l̇\n",
    "    end\n",
    "    \n",
    "    W /= kernel_matrix(X, X, ℓ=ℓ, σref=σref)\n",
    "    z = copy(ẏ)\n",
    "    \n",
    "    for i = 1:size(X)[2]\n",
    "        for j = 1:size(X)[2]\n",
    "            z[i] -= δk(X[:, i], X[:, j]) * l̇ * c[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    δ∇μx += W*z\n",
    "    \n",
    "    return δ∇μx\n",
    "end\n",
    "\n",
    "l̇ = rand()\n",
    "ẏ = rand(length(c))\n",
    "c = kernel_matrix(X, X, ℓ=1.0) \\ y\n",
    "cplus = kernel_matrix(X, X, ℓ=1.0+h*l̇) \\ (y + h*ẏ)\n",
    "cminus = kernel_matrix(X, X, ℓ=1.0-h*l̇) \\ (y - h*ẏ)\n",
    "\n",
    "δμ_test = δμ(x, X, c, ẏ, l̇)\n",
    "fd_δμ = ( μ(x, X, cplus, ℓ=1.0+h*l̇) - μ(x, X, cminus, ℓ=1.0-h*l̇) ) / (2h)\n",
    "relerr = (δμ_test - fd_δμ) / δμ_test\n",
    "println(\"Fininte difference check for δμ: $relerr\")\n",
    "\n",
    "# Finite difference on δμ\n",
    "u = rand(length(x))\n",
    "δ∇μ_test = u'*δ∇μ(x, X, c, ẏ, l̇)\n",
    "fd_δ∇μ = ( δμ(x+h*u, X, c, ẏ, l̇) - δμ(x-h*u, X, c, ẏ, l̇) ) / (2h)\n",
    "relerr = (δ∇μ_test - fd_δ∇μ) / δ∇μ_test \n",
    "println(\"Fininte difference check for δ∇μ: $relerr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation derivatives\n",
    "\n",
    "The predictive variance is\n",
    "$$\n",
    "  \\sigma^2 = k_{xx} - k_{xX} K_{XX}^{-1} k_{Xx}.\n",
    "$$\n",
    "Differentiating the predictive variance twice in space --- assuming $k_{xx}$ is independent of $x$ by stationarity ---\n",
    "gives us\n",
    "$$\\begin{aligned}\n",
    "  2 \\sigma \\sigma_{,i} &= -2 k_{xX,i} K_{XX}^{-1} k_{Xx} = -2 k_{xX,i} d \\\\\n",
    "  2 \\sigma_{,i} \\sigma_{,j} + 2 \\sigma \\sigma_{,ij} &= -2 k_{xX,ij} K_{XX}^{-1} k_{Xx} - 2 k_{xX,i} K_{XX}^{-1} k_{Xx,j} \\\\\n",
    "                     &= -2 k_{xX,ij} d -2 k_{xX,i} w^{(j)}\n",
    "\\end{aligned}$$\n",
    "Rearranging to get spatial derivatives of $\\sigma$ on their own gives us\n",
    "$$\\begin{aligned}\n",
    "  \\sigma_{,i} &= -\\sigma^{-1} k_{xX,i} d \\\\\n",
    "  \\sigma_{,ij} &= -\\sigma^{-1} \\left[ k_{xX,ij} d + k_{xX,i} w^{(j)} + \\sigma_{,i} \\sigma_{,j} \\right].\n",
    "\\end{aligned}$$\n",
    "\n",
    "Differentiating with respect to data (and locations) and kernel hypers requires more work.  First, note that\n",
    "$$\\begin{aligned}\n",
    "  2 \\sigma \\dot{\\sigma} \n",
    "  &= \\dot{k}_{xx} - 2 \\dot{k}_{xX} K_{XX}^{-1} k_{Xx} + k_{xX} K_{XX}^{-1} \\dot{K}_{XX} K_{XX}^{-1} k_{Xx} \\\\\n",
    "  &= \\dot{k}_{xx} - 2 \\dot{k}_{xX} d + d^T \\dot{K}_{XX} d\n",
    "\\end{aligned}$$\n",
    "Now, differentiating $\\sigma^{-1}$ with respect to data and hypers gives\n",
    "$$\\begin{aligned}\n",
    "  \\dot{\\sigma}_{,i} \n",
    "  &= \\sigma^{-2} \\dot{\\sigma} k_{xX,i} K_{XX}^{-1} k_{Xx} -\n",
    "     \\sigma^{-1} \\left[ \n",
    "       \\dot{k}_{xX,i} K_{XX}^{-1} k_{Xx} +\n",
    "       k_{xX,i} K_{XX}^{-1} \\dot{k}_{Xx} -\n",
    "       k_{xX} K_{XX}^{-1} \\dot{K}_{XX} K_{XX}^{-1} k_{Xx} \\right] \\\\\n",
    "  &= -\\sigma^{-1} \\left[ \\dot{\\sigma} \\sigma_{,i} + \\dot{k}_{xX,i} d + (w^{(i)})^T \\dot{k}_{Xx} - (w^{(i)})^T \\dot{K}_{XX} d \\right]\n",
    "\\end{aligned}$$\n",
    "\n",
    "<!-- My results when differentiating $\\sigma^{-1}$ with respect to data and hypers gives\n",
    "$$\\begin{aligned}\n",
    "  \\dot{\\sigma}_{,i} &= -\\sigma^{-1} \\left[ \\dot{\\sigma} \\sigma_{,i} -\n",
    "                       (w^{(i)})^T \\dot{K}_{XX} d + (w^{(i)})^T \\dot{k}_{Xx} + \\dot{K}_{xX,i}d\n",
    "  \\right]\n",
    "\\end{aligned}$$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finite difference check on ∇σ: -9.012165269543897e-10\n",
      "Finite difference check on Hσ: -2.8210343854467204e-7\n",
      "Finite difference check on Hσ again: -2.753599214405475e-8\n",
      "Finite difference check on δσ: -2.841362225328485e-10\n",
      "Finite difference check on δ∇σ: 7.598709234357712e-9\n"
     ]
    }
   ],
   "source": [
    "function Hσ(x, X; ℓ=1.0, σref=1.0)\n",
    "    Hσx = zeros(length(x), length(x))\n",
    "    KXx = kernel_matrix(X, reshape(x, length(x), 1))\n",
    "    d = kernel_matrix(X, X) \\ KXx\n",
    "    \n",
    "    W = zeros(size(X))\n",
    "    for col = 1:size(W)[2]\n",
    "       W[:, col] = ∇k(x, X[:, col]) \n",
    "    end\n",
    "    W /= kernel_matrix(X, X, ℓ=ℓ, σref=σref)\n",
    "    \n",
    "    for i = 1:size(X)[2]\n",
    "        Hσx += Hk(x, X[:, i])*d[i] + ∇k(x, X[:, i])*W[:, i]'\n",
    "    end\n",
    "    \n",
    "    Hσx += ∇σ(x, X)*∇σ(x, X)'\n",
    "    Hσx ./= -σ(x, X)\n",
    "    \n",
    "    return Hσx\n",
    "end\n",
    "\n",
    "function δ∇σ(x, X, l̇; ℓ=1.0, σref=1.0)\n",
    "    δ∇σx = δσ(x, X, l̇) * ∇σ(x, X)\n",
    "    KXX = kernel_matrix(X, X)\n",
    "    KXx = kernel_matrix(X, reshape(x, length(x), 1))\n",
    "    d = KXX \\ KXx\n",
    "    \n",
    "    W = zeros(size(X))\n",
    "    for ndx = 1:size(X)[2]\n",
    "        W[:, ndx] = ∇k(x, X[:, ndx])\n",
    "    end\n",
    "    W /= kernel_matrix(X, X, ℓ=ℓ, σref=σref)\n",
    "    \n",
    "    z0 = zeros(length(x))\n",
    "    z1 = zeros(size(X)[2])\n",
    "    z2 = zeros(size(X)[2])\n",
    "    \n",
    "    for i = 1:size(X)[2]\n",
    "        z0 += δ∇k(x, X[:, i]) * d[i] * l̇\n",
    "        z2[i] = δk(x, X[:, i]) * l̇\n",
    "        for j = 1:size(X)[2]\n",
    "            z1[i] += δk(X[:, i], X[:, j]) * d[j] * l̇\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    δ∇σx += -W*z1 + W*z2 + z0\n",
    "    δ∇σx /= -σ(x, X)\n",
    "\n",
    "    return δ∇σx\n",
    "end\n",
    "\n",
    "function δ∇σ(x, X, l̇; ℓ=1.0, σref=1.0)\n",
    "    δ∇σx = δσ(x, X, l̇) * ∇σ(x, X)\n",
    "    KXX = kernel_matrix(X, X)\n",
    "    KXx = kernel_matrix(X, reshape(x, length(x), 1))\n",
    "    d = KXX \\ KXx\n",
    "    \n",
    "    W = zeros(size(X))\n",
    "    for ndx = 1:size(X)[2]\n",
    "        W[:, ndx] = ∇k(x, X[:, ndx])\n",
    "    end\n",
    "    W /= kernel_matrix(X, X, ℓ=ℓ, σref=σref)\n",
    "    \n",
    "    z0 = zeros(length(x))\n",
    "    z1 = zeros(size(X)[2])\n",
    "    z2 = zeros(size(X)[2])\n",
    "    \n",
    "    for i = 1:size(X)[2]\n",
    "        z0 += δ∇k(x, X[:, i]) * d[i] * l̇\n",
    "        z2[i] = δk(x, X[:, i]) * l̇\n",
    "        for j = 1:size(X)[2]\n",
    "            z1[i] += δk(X[:, i], X[:, j]) * d[j] * l̇\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    δ∇σx += -W*z1 + W*z2 + z0\n",
    "    δ∇σx /= -σ(x, X)\n",
    "\n",
    "    return δ∇σx\n",
    "end\n",
    "\n",
    "function δσ(x, X, l̇; ℓ=1.0, σref=1.0)\n",
    "    δσx = δk(x, x) * l̇\n",
    "    KXX = kernel_matrix(X, X)\n",
    "    KXx = kernel_matrix(X, reshape(x, length(x), 1))\n",
    "    d = KXX \\ KXx\n",
    "    \n",
    "    for i = 1:size(X)[2]\n",
    "        δσx -= 2δk(x, X[:, i]) * d[i] * l̇\n",
    "        for j = 1:size(X)[2]\n",
    "            δσx += d[i] * d[j] * δk(X[:, i], X[:, j]) * l̇\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    δσx /= 2σ(x, X)\n",
    "    return δσx\n",
    "end\n",
    "\n",
    "function σ(x, X; ℓ=1.0, σref=1.0)\n",
    "    KXX = kernel_matrix(X, X, ℓ=ℓ, σref=σref)\n",
    "    KXx = kernel_matrix(X, reshape(x, length(x), 1), ℓ=ℓ, σref=σref)\n",
    "    return √(k(x, x) - dot(KXx, KXX \\ KXx))\n",
    "end\n",
    "\n",
    "function ∇σ(x, X; ℓ=1.0, σref=1.0)\n",
    "    ∇σx = zeros(length(x))\n",
    "    KXx = kernel_matrix(X, reshape(x, length(x), 1))\n",
    "    d = kernel_matrix(X, X) \\ KXx\n",
    "    \n",
    "    for i = 1:size(X)[2]\n",
    "        ∇σx += d[i] * ∇k(x, X[:, i], ℓ=ℓ, σref=σref)\n",
    "    end\n",
    "    \n",
    "    ∇σx /= -σ(x, X, ℓ=ℓ, σref=σref)\n",
    "    \n",
    "    return ∇σx\n",
    "end\n",
    "\n",
    "# Finite difference check on σ wrt to spatial coordinates\n",
    "u = rand(length(x))\n",
    "∇σ_test = u'*∇σ(x, X)\n",
    "fd_dσ_du = ( σ(x+h*u, X) - σ(x-h*u, X) ) / (2h)\n",
    "relerr = (∇σ_test - fd_dσ_du) / ∇σ_test\n",
    "println(\"Finite difference check on ∇σ: $relerr\")\n",
    "\n",
    "# Finite difference check (of hessian) on σ wrt to spatial coordinates\n",
    "u = rand(length(x))\n",
    "Hσ_test = u'*Hσ(x, X)*u\n",
    "fd_d2σ_du2 = ( σ(x+2h*u, X) - 2σ(x, X) + σ(x-2h*u, X) ) / (4h^2)\n",
    "relerr = (Hσ_test - fd_d2σ_du2) / Hσ_test\n",
    "println(\"Finite difference check on Hσ: $relerr\")\n",
    "\n",
    "# Finite difference check (of hessian) against gradient\n",
    "fd_∇σ_du = u' * ( ∇σ(x+h*u, X) - ∇σ(x-h*u, X) ) / (2h)\n",
    "relerr = (Hσ_test - fd_∇σ_du) / Hσ_test\n",
    "println(\"Finite difference check on Hσ again: $relerr\")\n",
    "\n",
    "# Finite difference check wrt to hypers\n",
    "l̇ = rand()\n",
    "δσ_test = δσ(x, X, l̇)\n",
    "fd_δσ_dl = ( σ(x, X; ℓ=1.0+h*l̇) - σ(x, X; ℓ=1.0-h*l̇) ) / (2h)\n",
    "relerr = (δσ_test - fd_δσ_dl) / δσ_test\n",
    "println(\"Finite difference check on δσ: $relerr\")\n",
    "\n",
    "# Finite difference check on δσ\n",
    "l̇ = rand()\n",
    "u = rand(length(x))\n",
    "δ∇σ_test = dot(u, δ∇σ(x, X, l̇))\n",
    "fd_δ∇σ_dx = ( δσ(x+h*u, X, l̇) - δσ(x-h*u, X, l̇) ) / (2h)\n",
    "relerr = (δ∇σ_test - fd_δ∇σ_dx) / δ∇σ_test\n",
    "println(\"Finite difference check on δ∇σ: $relerr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       "  0.2468524817303036\n",
       " -0.22176500826192783\n",
       "  0.42046714402348284"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "δ∇σ(x, X, l̇)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiating $z$\n",
    "\n",
    "Now consider $z = \\sigma^{-1} [\\mu - f^+ - \\xi]$.  As before, we begin with spatial derivatives:\n",
    "$$\\begin{aligned}\n",
    "  z_{,i} &= -\\sigma^{-2} \\sigma_{,i} [\\mu - f^+ - \\xi] + \\sigma^{-1} \\mu_{,i} \\\\\n",
    "         &= \\sigma^{-1} \\left[ \\mu_{,i} - \\sigma_{,i} z \\right] \\\\\n",
    "  z_{,ij} &= -\\sigma^{-2} \\sigma_{,j} \\left[ \\mu_{,i} - \\sigma_{,i} z \\right] + \n",
    "             \\sigma^{-1} \\left[\\mu_{,ij} - \\sigma_{,ij} z - \\sigma_{,i} z_{,j} \\right] \\\\\n",
    "          &= \\sigma^{-1} \\left[ \\mu_{,ij} - \\sigma_{,ij} z - \\sigma_{,i} z_{,j} - \\sigma_{,j} z_{,i} \\right]\n",
    "\\end{aligned}$$\n",
    "Now we differentiate with respect to data and hypers:\n",
    "$$\\begin{aligned}\n",
    "  \\dot{z} &= -\\sigma^{-2} \\dot{\\sigma} [\\mu - f^+ - \\xi] + \\sigma^{-1} [\\dot{\\mu} - \\dot{f}^+ - \\dot{\\xi}] \\\\\n",
    "          &= \\sigma^{-1} [\\dot{\\mu} - \\dot{f}^+ - \\dot{\\xi} - \\dot{\\sigma} z] \\\\\n",
    "  \\dot{z}_{,i} &= \\sigma^{-1} [\\dot{\\mu}_{,i} -\\dot{\\sigma}_{,i} z - \\dot{\\sigma} z_{,i} -\\sigma_{,i} \\dot{z}]\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finite difference check for ∇z: 9.34450439965713e-11\n",
      "Finite difference check for Hz again: 8.066533776741031e-8\n",
      "Finite difference check for δz: -2.2242455623232144e-10\n",
      "Finite difference check for δ∇z: 1.1903687708427678e-8\n"
     ]
    }
   ],
   "source": [
    "z(x, X, c, f⁺, ξ; ℓ=1.0, σref=1.0) = (1/σ(x, X, ℓ=ℓ, σref=σref)) * (μ(x, X, c, ℓ=ℓ, σref=σref) - f⁺ - ξ)\n",
    "∇z(x, X, c, f⁺, ξ; ℓ=1.0, σref=1.0) = (1/σ(x, X, ℓ=ℓ, σref=σref)) * (∇μ(x, X, c, ℓ=ℓ, σref=σref) - ∇σ(x, X, ℓ=ℓ, σref=σref)\n",
    "    * z(x, X, c, f⁺, ξ, ℓ=ℓ, σref=σref)\n",
    ")\n",
    "Hz(x, X, c, f⁺, ξ; ℓ=1.0, σref=1.0) = (1/σ(x, X, ℓ=ℓ, σref=σref)) * (\n",
    "    Hμ(x, X, c, ℓ=ℓ, σref=σref) - Hσ(x, X, ℓ=ℓ, σref=σref)*z(x, X, c, f⁺, ξ, ℓ=ℓ, σref=σref) - \n",
    "    ∇σ(x, X, ℓ=ℓ, σref=σref)*∇z(x, X, c, f⁺, ξ, ℓ=ℓ, σref=σref)' - (∇z(x, X, c, f⁺, ξ, ℓ=ℓ, σref=σref)*∇σ(x, X, ℓ=ℓ, σref=σref)')\n",
    ")\n",
    "δz(x, X, c, f⁺, ξ, l̇, ẏ; ḟ⁺=0.0, ξ̇=0.0, ℓ=1.0, σref=1.0) = (1/σ(x, X, ℓ=ℓ, σref=σref)) * (\n",
    "    δμ(x, X, c, ẏ, l̇, ℓ=ℓ, σref=σref) - ḟ⁺ - ξ̇ - δσ(x, X, l̇, ℓ=ℓ, σref=σref)*z(x, X, c, f⁺, ξ, ℓ=ℓ, σref=σref)\n",
    ")\n",
    "δ∇z(x, X, c, f⁺, ξ, l̇, ẏ; ḟ⁺=0.0, ξ̇=0.0, ℓ=1.0, σref=1.0) = (1/σ(x, X, ℓ=ℓ, σref=σref)) * (\n",
    "    δ∇μ(x, X, c, ẏ, l̇, ℓ=ℓ, σref=σref) - δ∇σ(x, X, l̇, ℓ=ℓ, σref=σref)*z(x, X, c, f⁺, ξ, ℓ=ℓ, σref=σref) -\n",
    "    δσ(x, X, l̇, ℓ=ℓ, σref=σref)*∇z(x, X, c, f⁺, ξ, ℓ=ℓ, σref=σref) - ∇σ(x, X, ℓ=ℓ, σref=σref)*δz(x, X, c, f⁺, ξ, l̇, ẏ, ḟ⁺=ḟ⁺, ξ̇=ξ̇, ℓ=ℓ, σref=σref)\n",
    ")\n",
    "\n",
    "# Finite difference check for ∇z\n",
    "u = rand(length(x))\n",
    "f⁺, ξ = [0.0, 0.0]\n",
    "∇z_test = dot(u, ∇z(x, X, c, f⁺, ξ))\n",
    "fd_dz_dx = ( z(x+h*u, X, c, f⁺, ξ) - z(x-h*u, X, c, f⁺, ξ) ) / (2h)\n",
    "relerr = (∇z_test - fd_dz_dx) / ∇z_test\n",
    "println(\"Finite difference check for ∇z: $relerr\")\n",
    "\n",
    "# Finite difference check for Hz\n",
    "# Hz_test = u'*Hz(x, X, c, f⁺, ξ)*u\n",
    "# fd_d2z_dx2 = ( z(x+2h*u, X, c, f⁺, ξ) - 2z(x, X, c, f⁺, ξ) + z(x-2h*u, X, c, f⁺, ξ) ) / (4h^2)\n",
    "# relerr = (Hz_test - fd_d2z_dx2) / Hz_test\n",
    "# println(\"Finite difference check for Hz: $relerr\")\n",
    "\n",
    "# Finite difference check for Hz using ∇z\n",
    "Hz_test = u'*Hz(x, X, c, f⁺, ξ)*u\n",
    "fd_∇z_du = u' * ( ∇z(x+h*u, X, c, f⁺, ξ) - ∇z(x-h*u, X, c, f⁺, ξ) ) / (2h)\n",
    "relerr = (Hz_test - fd_∇z_du) / Hz_test\n",
    "println(\"Finite difference check for Hz again: $relerr\")\n",
    "\n",
    "# Finite difference check for δz\n",
    "l̇ = rand()\n",
    "ẏ = rand(length(y))\n",
    "cplus = kernel_matrix(X, X, ℓ=1.0+h*l̇) \\ (y + h*ẏ)\n",
    "cminus = kernel_matrix(X, X, ℓ=1.0-h*l̇) \\ (y - h*ẏ)\n",
    "δz_test = δz(x, X, c, f⁺, ξ, l̇, ẏ)\n",
    "fd_dz_dl = ( z(x, X, cplus, f⁺, ξ, ℓ=1.0+h*l̇) - z(x, X, cminus, f⁺, ξ, ℓ=1.0-h*l̇) ) / (2h)\n",
    "relerr = (δz_test - fd_dz_dl) / δz_test\n",
    "println(\"Finite difference check for δz: $relerr\")\n",
    "\n",
    "# Finite difference check for mixed derivative δ∇z\n",
    "δ∇z_test = u' * δ∇z(x, X, c, f⁺, ξ, l̇, ẏ)\n",
    "# fd_∇z_dl = u' * ( ∇z(x, X, cplus, f⁺, ξ, ℓ=1.0+h*l̇) - ∇z(x, X, cminus, f⁺, ξ, ℓ=1.0-h*l̇) ) / (2h)\n",
    "fd_δz_dx = ( δz(x+h*u, X, c, f⁺, ξ, l̇, ẏ) - δz(x-h*u, X, c, f⁺, ξ, l̇, ẏ) ) / (2h)\n",
    "# relerr = (δ∇z_test - fd_∇z_dl) / δ∇z_test\n",
    "orelerr = (δ∇z_test - fd_δz_dx) / δ∇z_test\n",
    "# println(\"Finite difference check for δ∇z: $relerr\")\n",
    "println(\"Finite difference check for δ∇z: $orelerr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiating $\\alpha$\n",
    "\n",
    "Finally, we differentiate $\\alpha = \\sigma g(z)$.  As before, we start with spatial derivatives:\n",
    "$$\\begin{aligned}\n",
    "  \\alpha_{,i} &= \\sigma_{,i} g(z) + \\sigma g'(z) z_{,i} \\\\\n",
    "  \\alpha_{,ij} &= \\sigma_{,ij} g(z) + \\sigma_{,i} g'(z) z_{,j} + \\sigma_{,j} g'(z) z_{,i} + \\sigma g'(z) z_{,ij} + \\sigma g''(z) z_{,i} z_{,j} \\\\\n",
    "  &= \\sigma_{,ij} g(z) + [\\sigma_{,i} z_{,j} + \\sigma_{,j} z_{,i} + \\sigma z_{,ij}] g'(z) + \\sigma g''(z) z_{,i} z_{,j}\n",
    "\\end{aligned}$$\n",
    "We also may want the mixed derivative with respect to spatial coordinates and data and hypers:\n",
    "$$\\begin{aligned}\n",
    "  \\dot{\\alpha}_{,i} &= \\dot{\\sigma}_{,i} g(z) + \\sigma_{,i} g'(z) \\dot{z} + \\dot{\\sigma} g'(z) z_{,i} + \\sigma g''(z) \\dot{z} z_{,i} + \\sigma g'(z) \\dot{z}_{,i}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Finally, we differentiate $g(z) = z \\Phi(z) + \\phi(z)$, noting that\n",
    "$\\phi'(z) = -z \\phi(z)$ and $\\Phi'(z) = \\phi(z)$.  This gives\n",
    "$$\\begin{aligned}\n",
    "  g(z) &= z \\Phi(z) + \\phi(z) \\\\\n",
    "  g'(z) &= \\Phi(z) + z \\phi(z) + \\phi'(z) = \\Phi(z) \\\\\n",
    "  g''(z) &= \\phi(z).\n",
    "\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finite difference check for g: 2.3305801732931286e-12\n",
      "Finite difference check for dg: 1.6494457623861254e-9\n"
     ]
    }
   ],
   "source": [
    "g(z) = z * cdf(Normal(), z) + pdf(Normal(), z)\n",
    "dg(z) = cdf(Normal(), z)\n",
    "d2g(z) = pdf(Normal(), z)\n",
    "\n",
    "# Finite difference check of g\n",
    "z0 = z(x, X, c, f⁺, ξ; ℓ=1.0, σref=1.0)\n",
    "dg_test = dg(z0)\n",
    "fd_dg_dz = ( g(z0+h) - g(z0-h) ) / (2h)\n",
    "relerr = (dg_test - fd_dg_dz) / dg_test\n",
    "println(\"Finite difference check for g: $relerr\")\n",
    "\n",
    "z0 = 0.1\n",
    "d2g_test = d2g(z0)\n",
    "fd_d2g_dz2 = ( dg(z0+h) - dg(z0-h) ) / (2h)\n",
    "relerr = (d2g_test - fd_d2g_dz2) / d2g_test\n",
    "println(\"Finite difference check for dg: $relerr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finite difference check for ∇α: 2.4928423247103463e-9\n",
      "Finite difference check for Hα: 6.526004505476925e-8\n",
      "Finite difference check for δ∇α: -8.818963834969037e-9\n"
     ]
    }
   ],
   "source": [
    "function δ∇α(x, X, c, f⁺, ξ, l̇, ẏ; ḟ⁺=0.0, ξ̇=0.0, ℓ=1.0, σref=1.0)\n",
    "    z0 = z(x, X, c, f⁺, ξ; ℓ=ℓ, σref=σref)\n",
    "    gprime = dg(z0)\n",
    "    ∇zx = ∇z(x, X, c, f⁺, ξ; ℓ=ℓ, σref=σref)\n",
    "    δzx = δz(x, X, c, f⁺, ξ, l̇, ẏ, ḟ⁺=ḟ⁺, ξ̇=ξ̇, ℓ=ℓ, σref=σref)\n",
    "    σx = σ(x, X, ℓ=ℓ, σref=σref)\n",
    "    \n",
    "    return δ∇σ(x, X, l̇, ℓ=ℓ, σref=σref)*g(z0) + ∇σ(x, X, ℓ=ℓ, σref=σref)*gprime*δzx +\n",
    "    δσ(x, X, l̇, ℓ=ℓ, σref=σref)*gprime*∇zx + σx*d2g(z0)*δzx*∇zx + σx*gprime*δ∇z(x, X, c, f⁺, ξ, l̇, ẏ, ḟ⁺=ḟ⁺, ξ̇=ξ̇, ℓ=ℓ, σref=σref)\n",
    "end\n",
    "\n",
    "α(x, X, c, f⁺, ξ; ℓ=1.0, σref=1.0) = σ(x, X) * g(z(x, X, c, f⁺, ξ; ℓ=1.0, σref=1.0))\n",
    "\n",
    "function ∇α(x, X, c, f⁺, ξ; ℓ=1.0, σref=1.0)\n",
    "    z0 = z(x, X, c, f⁺, ξ; ℓ=ℓ, σref=σref)\n",
    "    return ∇σ(x, X, ℓ=ℓ, σref=σref)*z0 + σ(x, X, ℓ=ℓ, σref=σref)*dg(z0)*∇z(x, X, c, f⁺, ξ; ℓ=ℓ, σref=σref)\n",
    "end\n",
    "\n",
    "function Hα(x, X, c, f⁺, ξ; ℓ=1.0, σref=1.0)\n",
    "    z0 = z(x, X, c, f⁺, ξ; ℓ=ℓ, σref=σref)\n",
    "    ∇zx = ∇z(x, X, c, f⁺, ξ, ℓ=ℓ, σref=σref)\n",
    "    ∇σx = ∇σ(x, X, ℓ=ℓ, σref=σref)\n",
    "    σx = σ(x, X, ℓ=ℓ, σref=σref)\n",
    "    Hzx = Hz(x, X, c, f⁺, ξ; ℓ=ℓ, σref=σref)\n",
    "    \n",
    "    return Hσ(x, X, ℓ=ℓ, σref=σref)*g(z0) + (∇σx*∇zx' + ∇zx*∇σx' + σx * Hzx)*dg(z0) + σx*d2g(z0)*∇zx*∇zx'\n",
    "end\n",
    "\n",
    "# Finite difference check of ∇α\n",
    "u = rand(length(x))\n",
    "∇α_test = dot(u, ∇α(x, X, c, f⁺, ξ, ℓ=1.0, σref=1.0))\n",
    "fd_dα_dx = ( α(x+h*u, X, c, f⁺, ξ; ℓ=1.0, σref=1.0) - α(x-h*u, X, c, f⁺, ξ; ℓ=1.0, σref=1.0) ) / (2h)\n",
    "relerr = (∇α_test - fd_dα_dx) / ∇α_test\n",
    "println(\"Finite difference check for ∇α: $relerr\")\n",
    "\n",
    "# Finite difference check of Hα\n",
    "Hα_test = dot(u, u'*Hα(x, X, c, f⁺, ξ, ℓ=1.0, σref=1.0))\n",
    "fd_d2α_dx2 = u' * ( ∇α(x+h*u, X, c, f⁺, ξ; ℓ=1.0, σref=1.0) - ∇α(x-h*u, X, c, f⁺, ξ; ℓ=1.0, σref=1.0) ) / (2h)\n",
    "relerr = (Hα_test - fd_d2α_dx2) / Hα_test\n",
    "println(\"Finite difference check for Hα: $relerr\")\n",
    "\n",
    "# Finite difference check for δ∇α\n",
    "l̇ = rand()\n",
    "ẏ = rand(length(y))\n",
    "cplus = kernel_matrix(X, X, ℓ=1.0+h*l̇) \\ (y + h*ẏ)\n",
    "cminus = kernel_matrix(X, X, ℓ=1.0-h*l̇) \\ (y - h*ẏ)\n",
    "δ∇α_test = u' * δ∇α(x, X, c, f⁺, ξ, l̇, ẏ, ḟ⁺=0.0, ξ̇=0.0, ℓ=1.0, σref=1.0)\n",
    "fd_∇α_dl = u' * ( ∇α(x, X, cplus, f⁺, ξ; ℓ=1.0+h*l̇, σref=1.0) - ∇α(x, X, cminus, f⁺, ξ; ℓ=1.0-h*l̇, σref=1.0) ) / (2h)\n",
    "relerr = (δ∇α_test - fd_∇α_dl) / δ∇α_test\n",
    "println(\"Finite difference check for δ∇α: $relerr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia nodeps 1.10.5",
   "language": "julia",
   "name": "julia-nodeps-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
