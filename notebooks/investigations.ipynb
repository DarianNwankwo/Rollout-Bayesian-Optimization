{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94e82d3-4cd0-436f-ba94-021baaaa69f9",
   "metadata": {},
   "source": [
    "## Observations\n",
    "1. Our gradient estimates at known sample locations are large when we resample at the sample location in our trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c83066d-0b79-44d2-8a09-8a7c34e4984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Plots\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d60d606-78e5-46fb-8876-755999ab9b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_gradient_ascent_adam (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../rollout.jl\")\n",
    "include(\"../testfns.jl\")\n",
    "include(\"../utils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c376d4f1-0fb0-48d3-921a-a2f360220656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestFunction(4, [-500.0 500.0; -500.0 500.0; -500.0 500.0; -500.0 500.0], ([420.9687, 420.9687, 420.9687, 420.9687],), var\"#f#806\"{Int64}(4), var\"#∇f#807\"{Int64}(4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testfn = TestLinearCosine1D(1, 25, lb=0., ub=2)\n",
    "# testfn = TestQuadratic1D(1., 0., 0.; lb=-1., ub=1.)\n",
    "# testfn = TestConstant(0., lbs=[0.], ubs=[1.])\n",
    "# testfn = TestGramacyLee()\n",
    "testfn = TestSchwefel(4)\n",
    "# tplot(testfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae5c0c0-adad-4b39-86dc-095ef34968dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1906)\n",
    "\n",
    "n, h, σn2 = 1, 1, 1e-6\n",
    "MC_SAMPLES = 25\n",
    "# Setup low discrepancy random number stream\n",
    "lds_rns = gen_low_discrepancy_sequence(MC_SAMPLES, testfn.dim, h+1);\n",
    "rns = randn(MC_SAMPLES, testfn.dim+1, h+1);\n",
    "xmin, xmax, d = (testfn.bounds[1], testfn.bounds[2], size(testfn.bounds, 1))\n",
    "θ = [1.]\n",
    "ψ = kernel_matern52(θ)\n",
    "# ψ = kernel_scale(kernel_matern52, [5., θ...])\n",
    "\n",
    "lbs, ubs = testfn.bounds[:,1], testfn.bounds[:,2]\n",
    "ϵ, num_starts = 1e-6, 4\n",
    "s = SobolSeq(lbs, ubs)\n",
    "\n",
    "xstarts = reduce(hcat, next!(s) for i = 1:num_starts)\n",
    "xstarts = hcat(xstarts, lbs .+ ϵ)\n",
    "xstarts = hcat(xstarts, ubs .- ϵ);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9acff-0e5d-4b99-a625-59eb4c48f72e",
   "metadata": {},
   "source": [
    "### Dense Experiments in 1D for Rollout Acquisition Functions\n",
    "We'll do a comparative analysis, visually, of the structure of the rollout acquisition function in 1D for horizons 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8535a0cf-4084-4d84-b63d-c7f0ee8bed31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RBFsurrogate(RBFfun([1.0], var\"#ψ#451\"{var\"#k#461\", Vector{Float64}}(var\"#k#461\"(), [1.0]), var\"#Dρ_ψ#452\"{var\"#ψ#451\"{var\"#k#461\", Vector{Float64}}}(var\"#ψ#451\"{var\"#k#461\", Vector{Float64}}(var\"#k#461\"(), [1.0])), var\"#Dρρ_ψ#453\"{var\"#Dρ_ψ#452\"{var\"#ψ#451\"{var\"#k#461\", Vector{Float64}}}}(var\"#Dρ_ψ#452\"{var\"#ψ#451\"{var\"#k#461\", Vector{Float64}}}(var\"#ψ#451\"{var\"#k#461\", Vector{Float64}}(var\"#k#461\"(), [1.0]))), var\"#∇θ_ψ#454\"{var\"#k#461\", Vector{Float64}}(var\"#k#461\"(), [1.0])), [-391.15754060162743 0.0 0.0; 218.9031628453905 0.0 0.0; 82.66621969601522 0.0 0.0; 431.0582938270935 0.0 0.0], [1.000001 0.0 0.0; 0.0 1.000001 1.0; 0.0 1.0 1.000001], [1.000000499999875 0.0 0.0; 0.0 1.000000499999875 0.0; 0.0 0.999999500000375 0.0014142132088085626], [-195.4639666064238, 97.73198330321179, 97.73198330321179], [-195.46377114265263, 48.86596721281304, 48.86596722443153], 1.0e-6, 1578.199616696788)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [-391.15754060162743 0.0 0.0; 218.9031628453905 0.0 0.0; 82.66621969601522 0.0 0.0; 431.0582938270935 0.0 0.0]\n",
    "y = testfn(X)\n",
    "sur = fit_surrogate(ψ, X, y; σn2=σn2)\n",
    "# sur = optimize_hypers_optim(sur, kernel_matern52)\n",
    "\n",
    "# print(\"Rollout Evaluations: \")\n",
    "# # Dense Evaluation of Rollout Acquisition Function\n",
    "# for (i, x) in enumerate(domain)\n",
    "#     print(\"|\")\n",
    "#     x0 = [x]\n",
    "#     sx = sur(x0)\n",
    "\n",
    "#     tp = TrajectoryParameters(\n",
    "#         x0=x0, h=h, mc_iters=MC_SAMPLES,\n",
    "#         rnstream_sequence=lds_rns, lbs=lbs, ubs=ubs\n",
    "#     )\n",
    "#     # Monte-carlo integrate trajectory for x0\n",
    "#     μx, ∇μx, μ_stderr, ∇μ_stderr = simulate_trajectory(sur, tp, xstarts, variance_reduction=variance_reduction)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca67e26b-6c64-4e7f-ab9c-5a729f19bb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rollout_solver (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: We need to specify the maximum number of iterations and terminate if we exhaust our budget\n",
    "TODO: EI for Rosenbrock looks like zeros everywhere, depending on how we sample. I suspect this\n",
    "is why our algorithm halts here.\n",
    "\"\"\"\n",
    "function ei_solver(s::RBFsurrogate, lbs, ubs; initial_guesses, max_iterations=100)\n",
    "    fbest = minimum(get_observations(s))\n",
    "\n",
    "    function ei(x)\n",
    "        sx = s(x)\n",
    "        if sx.σ < 1e-6 return 0 end\n",
    "        return -sx.EI\n",
    "    end\n",
    "\n",
    "    function ei_grad!(g, x)\n",
    "        EIx = -s(x).∇EI\n",
    "        for i in eachindex(EIx)\n",
    "            g[i] = EIx[i]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    function ei_hessian!(h, x)\n",
    "        HEIx = -s(x).HEI\n",
    "        for row in 1:size(HEIx, 1)\n",
    "            for col in 1:size(HEIx, 2)\n",
    "                h[row, col] = HEIx[row, col]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    final_minimizer = (initial_guesses[:, 1], Inf)\n",
    "    \n",
    "    for j in 1:size(initial_guesses, 2)\n",
    "        initial_guess = initial_guesses[:, j]\n",
    "        df = TwiceDifferentiable(ei, ei_grad!, ei_hessian!, initial_guess)\n",
    "        dfc = TwiceDifferentiableConstraints(lbs, ubs)\n",
    "        result = optimize(df, dfc, initial_guess, IPNewton(), Optim.Options(iterations=max_iterations))\n",
    "        cur_minimizer, cur_minimum = Optim.minimizer(result), Optim.minimum(result)\n",
    "\n",
    "        if cur_minimum < final_minimizer[2]\n",
    "            final_minimizer = (cur_minimizer, cur_minimum)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return final_minimizer\n",
    "end\n",
    "\n",
    "function rollout_solver(;\n",
    "    sur::RBFsurrogate,\n",
    "    tp::TrajectoryParameters,\n",
    "    xstarts::Matrix{Float64},\n",
    "    batch::Matrix{Float64},\n",
    "    max_iterations::Int = 25,\n",
    "    varred::Bool = true,\n",
    "    )\n",
    "    batch_results = Array{Any, 1}(undef, size(batch, 2))\n",
    "\n",
    "    for i in 1:size(batch, 2)\n",
    "        # Update start of trajectory for each point in the batch\n",
    "        tp.x0 = batch[:, i]\n",
    "\n",
    "        # Perform stochastic gradient ascent on the point in the batch\n",
    "        batch_results[i] = stochastic_gradient_ascent_adam(\n",
    "            sur=sur,\n",
    "            tp=tp,\n",
    "            max_sgd_iters=max_iterations,\n",
    "            varred=varred,\n",
    "            xstarts=xstarts,\n",
    "        )\n",
    "    end\n",
    "\n",
    "    # Find the point in the batch that maximizes the rollout acquisition function\n",
    "    println(\"Number of Results: $(length(batch_results))\")\n",
    "    best_tuple = first(batch_results)\n",
    "    for result in batch_results[2:end]\n",
    "        if result.final_obj > best_tuple.final_obj\n",
    "            best_tuple = result\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return best_tuple.finish, best_tuple.final_obj\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7358999a-02dc-462a-abed-4f0b121de3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×18 Matrix{Float64}:\n",
       "  499.99   375.0   312.5  -250.0  …   -31.25   250.0    437.5   -312.5\n",
       "  312.5   -187.5  -125.0     0.0      -31.25  -187.5    250.0   -250.0\n",
       " -499.99   125.0     0.0   125.0       62.5    499.99  -187.5    -62.5\n",
       "  -62.5     62.5   375.0  -125.0     -375.0   -312.5    156.25   499.99"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allocate all initial samples\n",
    "initial_samples = randsample(1, testfn.dim, lbs, ubs)\n",
    "\n",
    "# Initialize the trajectory parameters\n",
    "tp = TrajectoryParameters(\n",
    "    initial_samples[:, 1], # Will be overriden later\n",
    "    h,\n",
    "    MC_SAMPLES,\n",
    "    lds_rns,\n",
    "    lbs,\n",
    "    ubs,\n",
    ")\n",
    "batch = shuffle(generate_batch(16, lbs=tp.lbs, ubs=tp.ubs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62aa46de-099c-4f61-9891-5157ed935783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
      "History: [-391.15754060162743 0.0 0.0 0.0 0.0 0.0 0.0 499.99 0.0; 218.9031628453905 0.0 0.0 0.0 0.0 0.0 0.0 312.5 0.0; 82.66621969601522 0.0 0.0 0.0 0.0 0.0 0.0 -499.99 0.0; 431.0582938270935 0.0 0.0 0.0 0.0 0.0 0.0 -62.5 0.0] -- Xnext: [0.0, 0.0, 0.0, 0.0]\n",
      "δxi_intermediates: [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0] -- HEI: [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0] -- EI: 0.0\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "SingularException(1)",
     "output_type": "error",
     "traceback": [
      "SingularException(1)",
      "",
      "Stacktrace:",
      "  [1] checknonsingular",
      "    @ /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/factorization.jl:19 [inlined]",
      "  [2] checknonsingular",
      "    @ /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/factorization.jl:22 [inlined]",
      "  [3] #lu!#170",
      "    @ /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/lu.jl:82 [inlined]",
      "  [4] lu!",
      "    @ /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/lu.jl:80 [inlined]",
      "  [5] lu!(A::Hermitian{Float64, Matrix{Float64}}, pivot::RowMaximum; check::Bool)",
      "    @ LinearAlgebra /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/lu.jl:87",
      "  [6] lu!",
      "    @ /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/lu.jl:85 [inlined]",
      "  [7] #lu#176",
      "    @ /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/lu.jl:299 [inlined]",
      "  [8] lu (repeats 2 times)",
      "    @ /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/lu.jl:298 [inlined]",
      "  [9] \\(A::Hermitian{Float64, Matrix{Float64}}, B::Matrix{Float64})",
      "    @ LinearAlgebra /Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/symmetric.jl:628",
      " [10] rollout!(T::Trajectory, lbs::Vector{Float64}, ubs::Vector{Float64}; rnstream::Matrix{Float64}, xstarts::Matrix{Float64})",
      "    @ Main ~/Documents/academia/cornell-university/research/projects/kernel-numerics-refactor-revamp/rollout.jl:128",
      " [11] rollout!",
      "    @ ~/Documents/academia/cornell-university/research/projects/kernel-numerics-refactor-revamp/rollout.jl:90 [inlined]",
      " [12] simulate_trajectory(s::RBFsurrogate, tp::TrajectoryParameters, xstarts::Matrix{Float64}; variance_reduction::Bool)",
      "    @ Main ~/Documents/academia/cornell-university/research/projects/kernel-numerics-refactor-revamp/rollout.jl:302",
      " [13] simulate_trajectory",
      "    @ ~/Documents/academia/cornell-university/research/projects/kernel-numerics-refactor-revamp/rollout.jl:290 [inlined]",
      " [14] stochastic_gradient_ascent_adam(; λ::Float64, β1::Float64, β2::Float64, ϵ::Float64, ftol::Float64, gtol::Float64, varred::Bool, sur::RBFsurrogate, tp::TrajectoryParameters, max_sgd_iters::Int64, xstarts::Matrix{Float64})",
      "    @ Main ~/Documents/academia/cornell-university/research/projects/kernel-numerics-refactor-revamp/utils.jl:257",
      " [15] stochastic_gradient_ascent_adam",
      "    @ ~/Documents/academia/cornell-university/research/projects/kernel-numerics-refactor-revamp/utils.jl:240 [inlined]",
      " [16] rollout_solver(; sur::RBFsurrogate, tp::TrajectoryParameters, xstarts::Matrix{Float64}, batch::Matrix{Float64}, max_iterations::Int64, varred::Bool)",
      "    @ Main ./In[37]:63",
      " [17] top-level scope",
      "    @ In[43]:4"
     ]
    }
   ],
   "source": [
    "include(\"../rollout.jl\")\n",
    "# Solve the acquisition function\n",
    "# xnext, fnext = ei_solver(sur, lbs, ubs; initial_guesses=xstarts)\n",
    "xnext, fnext = rollout_solver(sur=sur, tp=tp, xstarts=xstarts, batch=batch)\n",
    "ynext = testfn(xnext)\n",
    "# Update the surrogate model\n",
    "sur = update_surrogate(sur, xnext, ynext)\n",
    "sur = optimize_hypers_optim(sur, kernel_matern52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94e3a861-4421-47ac-bc2a-b57c2104f1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×7 Matrix{Float64}:\n",
       " -391.158   0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  218.903   0.0  0.0  0.0  0.0  0.0  0.0\n",
       "   82.6662  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  431.058   0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sur.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7203d6-acec-4cf7-b2b2-54cc7cc30bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
